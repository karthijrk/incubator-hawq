--
-- PXF HDFS extended regression suite
--
-- Prerequisites:
--
--   Must have a running hdfs with REST service on port 50070
--   Must have HADOOP_ROOT, HBASE_ROOT, HIVE_ROOT and ZOOKEEPER_ROOT set.
--
-- TODO: test gpdbwritable write/read when it is enabled.
-- TODO: test PB, AVRO, THRIFT when it is enabled (read only, with pre formatted files).
-- TODO: test protocol validator for pxf once written.
-- TODO: test parameter passing, filter passing
-- start_matchsubs
--                                                                                               
-- # create a match/subs expression to handle ip addresses that change
--
-- m/(ERROR|WARNING):.*remote component error.*\(\d+\).*from.*'\d+\.\d+\.\d+\.\d+:\d+'.*/
-- s/'\d+\.\d+\.\d+\.\d+:\d+'/'SOME_IP:SOME_PORT'/
--
-- end_matchsubs
-- start_matchignore
--
-- m/.*Unable to load native-hadoop library for your platform.*/
--
-- end_matchignore
--------------------------------------------------------------------------------
-- GPHDFS
--------------------------------------------------------------------------------
--
-- Load HDFS with test data
--
\! ${HADOOP_ROOT}/bin/hadoop fs -mkdir /gpdb_regression_data
\! sh @abs_srcdir@/helpers/create_table_file.sh @abs_srcdir@/data/pxf/multiblock.tbl
creating file @abs_srcdir@/data/pxf/multiblock.tbl
\! ${HADOOP_ROOT}/bin/hadoop fs -copyFromLocal @abs_srcdir@/data/pxf/multiblock.tbl /gpdb_regression_data/multiblock.tbl
--
-- Test multiblock file
--
CREATE EXTERNAL TABLE mbt(t1 text,
                          a1 integer)
LOCATION ('pxf://@hostname@:50070/gpdb_regression_data/multiblock.tbl?PROFILE=HdfsTextSimple')
FORMAT 'TEXT' (DELIMITER ',');
SELECT t1, a1 FROM mbt ORDER BY t1 LIMIT 10;
 t1 | a1 
----+----
 t1 |  1
 t1 |  1
 t1 |  1
 t1 |  1
 t1 |  1
 t1 |  1
 t1 |  1
 t1 |  1
 t1 |  1
 t1 |  1
(10 rows)

SELECT SUM(a1) from mbt;
     sum     
-------------
 16400384000
(1 row)

SELECT COUNT(*) FROM mbt;
  count   
----------
 32768000
(1 row)

SELECT cnt < 32768000 AS check FROM (SELECT COUNT(*) AS cnt FROM mbt WHERE gp_segment_id = 0) AS a;
 check 
-------
 t
(1 row)

DROP EXTERNAL TABLE mbt;
--
-- Test extensibility - read
--
CREATE EXTERNAL TABLE extens(num1   integer,
                             t1      text,
                             num2    integer)
LOCATION ('pxf://@hostname@:50070/regression_location?FRAGMENTER=DummyFragmenter&ACCESSOR=DummyAccessor&RESOLVER=DummyResolver&ANALYZER=DummyAnalyzer')
FORMAT 'custom' (formatter = 'pxfwritable_import');
SELECT num1, t1 FROM extens ORDER BY num1, t1;
 num1 |    t1     
------+-----------
    0 | fragment1
    0 | fragment2
    0 | fragment3
    1 | fragment1
    1 | fragment2
    1 | fragment3
(6 rows)

ANALYZE extens;
DROP EXTERNAL TABLE extens;
--
-- Test extensibility - write
--
CREATE WRITABLE EXTERNAL TABLE extens_write(t1 text, t2 text)
LOCATION ('pxf://@hostname@:50070/regression_location?ACCESSOR=DummyAccessor&RESOLVER=DummyResolver')
FORMAT 'custom' (formatter = 'pxfwritable_export');
INSERT INTO extens_write VALUES ('something', 'big'), ('is', 'going'), ('to', 'happen');
DROP EXTERNAL TABLE extens_write;
--
-- Cleanup: delete all data that was copied into hdfs
--
-- start_ignore
\! ${HADOOP_ROOT}/bin/hadoop fs -rm -r /gpdb_regression_data
Deleted /gpdb_regression_data
\! rm @abs_srcdir@/data/pxf/multiblock.tbl
-- end_ignore
