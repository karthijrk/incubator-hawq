#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Line too long - pylint: disable=C0301
# Invalid name  - pylint: disable=C0103
#
# Copyright (c) EMC 2011
# Copyright (c) Greenplum Inc 2010
# All Rights Reserved. 
#
"""
Activates a standby master instance when the primary master instance has 
failed.  Will stop the gpsyncmaster process, update the system catalog 
tables and start the instance with the standby master instance as the 
new master.
"""

import os
import sys
import signal
import glob
import time
import shutil
from datetime import datetime, timedelta

# import GPDB modules
try:
    from gppylib.commands import unix, gp, pg
    from gppylib.commands.gp import GpAddConfigScript
    from gppylib.db import dbconn
    from gppylib.gpparseopts import OptParser, OptChecker, OptionGroup, SUPPRESS_HELP
    from gppylib.gplog import get_default_logger, setup_tool_logging, enable_verbose_logging, get_logger_if_verbose
    from gppylib import gparray
    from gppylib.userinput import ask_yesno
    from gppylib.gp_dbid import writeGpDbidFile
    from gppylib.operations.filespace import PG_SYSTEM_FILESPACE, GP_TRANSACTION_FILES_FILESPACE, GP_TEMPORARY_FILES_FILESPACE, GetFilespaceEntries, GetFilespaceEntriesDict
    from gppylib.commands.base import WorkerPool
except ImportError, e_:
    sys.exit('ERROR: Cannot import modules.  Please check that you '
             'have sourced greenplum_path.sh.  Detail: ' + str(e_))

EXECNAME = os.path.split(__file__)[-1]

# Threshold values
LOG_TIME_THRESHOLD_MINS = 120


_description = sys.modules[__name__].__doc__
_usage = "\n"


class GpActivateStandbyException(Exception):
    "Generic exception for all things activatestandby"
    pass


#-------------------------------------------------------------------------
def parseargs():
    """Parses and validates command line args."""
    
    parser = OptParser(option_class=OptChecker,
                       description=' '.join(_description.split()),
                       version='%prog version $Revision$')
    parser.setHelp([])
    parser.remove_option('-h')
    
    # General options section
    optgrp = OptionGroup(parser, 'General options')
    optgrp.add_option('-h', '-?', '--help', dest='help', action='store_true',
                      help='display this help message and exit')
    optgrp.add_option('-v', dest='version', action='store_true',
                      help='display version information and exit')
    parser.add_option_group(optgrp)

    # Logging options section
    optgrp = OptionGroup(parser, 'Logging options')
    optgrp.add_option('-q', '--quiet', action='store_true',
                      help='quiet mode, do not log progress to screen')
    optgrp.add_option('-l', '--logfile', type='string', default=None,
                      help='alternative logfile directory')
    optgrp.add_option('-a', help='don\'t ask to confirm standby master activation',
                      dest='confirm', default=True, action='store_false')
    parser.add_option_group(optgrp)

    # Standby activation options section
    optgrp = OptionGroup(parser, 'Standby activation options')
    optgrp.add_option('-d', '--master-data-directory', dest='master_data_dir',
                      type='string', help='standby master data directory')
    optgrp.add_option('-f', '--force', action='store_true',
                      help='force activation if gpsyncmaster process not running')
    optgrp.add_option('-c', '--create-new-standby', type='string', dest='new_standby',
                      help='create a new standby master instance following successful '
                      'activation of the standby master instance', metavar='HOSTNAME')
    optgrp.add_option('--ignore', dest='ignore', type='string', help=SUPPRESS_HELP)
    parser.add_option_group(optgrp)
    
    parser.set_defaults(quiet=False, force=False)

    # Parse the command line arguments
    (options, args) = parser.parse_args()

    if options.help:
        parser.print_help()
        parser.exit(0, None)

    if options.version:
        parser.print_version()
        parser.exit(0, None)

    # check we got the -d option
    if not options.master_data_dir:
        logger.fatal('Required option -d is missing.')
        parser.exit(2, None)
        
    # We have to normalize this path for a later comparison
    options.master_data_dir = os.path.abspath(os.path.normpath(options.master_data_dir))

    # check that there isn't a conflict between -d option and MASTER_DATA_DIRECTORY env
    env_master_data_dir = os.getenv('MASTER_DATA_DIRECTORY', None)
    if not env_master_data_dir:
        logger.fatal('MASTER_DATA_DIRECTORY environment variable not set.')
        parser.exit(2, None)

    if os.path.normpath(env_master_data_dir) != options.master_data_dir:
        logger.fatal('Current setting of MASTER_DATA_DIRECTORY not same as -d parameter.')
        parser.exit(2, None)

    # check we aren't trying to create a standby master on this host
    if options.new_standby and unix.getLocalHostname() == options.new_standby:
        logger.fatal('New standby hostname supplied is same as current hostname.')
        parser.exit(2, None)

    # check new standby host is up
    if options.new_standby:
        cmd = unix.Ping('Check new standby host up', options.new_standby)
        cmd.run()
        if cmd.get_results().rc != 0:
            logger.fatal('New standby host %s did not respond to ping request.' % options.new_standby)
            parser.exit(2, None)

        # Check master data directory does not exist already on new standby
        if unix.FileDirExists.remote('Check new standby', options.new_standby, options.master_data_dir):
            logger.fatal('%s already exists on proposed new standby master %s' % \
                         (options.master_data_dir, options.new_standby))
            parser.exit(2, None)

    if options.logfile and not os.path.exists(options.logfile):
        logger.fatal('Log directory %s does not exist.' % options.logfile)
        parser.exit(2, None)

    # The default logging for gpactivatestandby is verbose
    if not options.quiet:
        enable_verbose_logging()

    # There shouldn't be any args
    if len(args) > 0:
        logger.error('Unknown arguments:')
        for arg in args:
            logger.error('  %s' % arg)
        parser.exit(2, None)
        
    return options, args


#-------------------------------------------------------------------------
def print_results(array, hostname, options):
    """Prints out the summary of the operation."""
    
    logger.info('-----------------------------------------------------')
    logger.info('The activation of the standby master has completed successfully.')
    logger.info('%s is now the new primary master.' % hostname)
    logger.info('You will need to update your user access mechanism to reflect')
    logger.info('the change of master hostname.')
    logger.info('Do not re-start the failed master while the fail-over master is')
    logger.info('operational, this could result in database corruption!')
    logger.info('MASTER_DATA_DIRECTORY is now %s if' % options.master_data_dir)
    logger.info('this has changed as a result of the standby master activation, remember')
    logger.info('to change this in any startup scripts etc, that may be configured')
    logger.info('to set this value.')
    if not options.new_standby:
        logger.info('New standby master not initialized!')
    else:
        logger.info('New standby master instance %s' % options.new_standby)
    logger.info('MASTER_PORT is now %d, if this has changed, you' % array.standbyMaster.getSegmentPort())
    logger.info('may need to make additional configuration changes to allow access')
    logger.info('to the Greenplum instance.')
    logger.info('Refer to the Administrator Guide for instructions on how to re-activate')
    logger.info('the master to its previous state once it becomes available.')
    logger.info('Query planner statistics must be updated on all databases')
    logger.info('following standby master activation.')
    logger.info('When convenient, run ANALYZE against all user databases.')
    logger.info('-----------------------------------------------------')


#-------------------------------------------------------------------------
def print_summary(options, warnings_errors, last_entry_time):
    # Too many statements - pylint: disable=R0915

    """Print summary of the action and asks user if they want to
    continue with the activation."""
    
    last_entry_ago = None
    require_force = False
    warnings_generated = False
    
    # calculate the timedelta of last log message
    if last_entry_time:
        last_entry_ago = datetime.now() - datetime.strptime(last_entry_time, '%Y-%m-%d %H:%M:%S.%f %Z')
        
    # check the syncmaster
    gpsyncmaster_running = check_gpsync_running(options)
    if not gpsyncmaster_running:
        require_force = True
        
    logger.info('-----------------------------------------------------')
    logger.info('Master data directory     = %s' % options.master_data_dir)
    if options.logfile:
        logger.info('Log directory             = %s' % options.logfile)
    logger.info('gpsyncmaster running      = %s' % ('yes' if gpsyncmaster_running else 'no'))
    logger.info('Last log entry time       = %s' % last_entry_time)
    if last_entry_ago:
        logger.info('                            %s ago' % last_entry_ago)
    logger.info('Create new standby master = %s' % ('yes' if options.new_standby else 'no'))
    if options.new_standby:
        logger.info('New standby master host   = %s' % options.new_standby)
    logger.info('Force standby activation  = %s' % ('yes' if options.force else 'no'))
    logger.info('-----------------------------------------------------')
    if last_entry_ago > timedelta(minutes=LOG_TIME_THRESHOLD_MINS):
        logger.warning('The last log entry timestamp was over %d minutes ago.' % LOG_TIME_THRESHOLD_MINS)
        logger.warning('This indicates that the standby master is likely out of date.')
        require_force = True
        warnings_generated = True
    if len(warnings_errors) > 0:
        logger.warning('The following warnings/errors were found in the most recent log file:')
        for log_msg in warnings_errors:
            logger.warning('  %s' % log_msg)

        logger.warning('Greenplum has detected errors and/or warnings in your standby')
        logger.warning('master log file that indicate a problem with the synchronization process')
        logger.warning('between your primary and standby master hosts. Before activating your')
        logger.warning('standby master, it is critical to ensure that it is up to date with all')
        logger.warning('of the transactions currently committed to Greenplum Database. If you')
        logger.warning('activate a standby master that is not in sync with the transactional')
        logger.warning('state of the segments, you may introduce catalog and data')
        logger.warning('inconsistencies that will render your Greenplum Database instance')
        logger.warning('unusable. If your primary master is no longer available and you suspect')
        logger.warning('that you do not have an up-to-date standby master, contact Greenplum')
        logger.warning('Customer Support for further assistance.')
        logger.warning('It is also recommended that you make a backup of the standby master')
        logger.warning('data directory (%s) before continuing.' % options.master_data_dir)
        
        require_force = True
        warnings_generated = True
    # Check if we require a force
    if require_force and not options.force:
        logger.warning('If you wish to continue you must use the -f option to force')
        logger.warning('the activation process.')
        warnings_generated = True
        raise GpActivateStandbyException('Force activation required')
    if options.confirm:
        yn = ask_yesno(None, 'Do you want to continue with standby master activation?', 'N')
        if not yn:
            raise GpActivateStandbyException('User canceled') 

    return warnings_generated


#-------------------------------------------------------------------------
def get_most_recent_log(options):
    """
    Returns the file name of the most recent log file.
    """
    file_pattern = options.master_data_dir + '/pg_log/gpdb*.csv'
    file_pair    = lambda f: (time.localtime(os.stat(f)[8]), f)
    file_list    = sorted([file_pair(f) for f in glob.glob(file_pattern)])
    if len(file_list) == 0:
        return None
    return file_list[-1][1]


#-------------------------------------------------------------------------
def setup_ignore_filter(options):
    """
    Returns ignore_filter function found in python file specified by options.ignore.
    """
    if not options.ignore:
        return None

    # load the filter from the file, giving it access to the logger
    #
    gdict = { 'logger':logger }
    try:
        execfile(options.ignore, gdict)
    except (OSError, IOError), e:
        logger.info('Could not read ignore_filter file: %s' % str(e))

    return gdict.get('ignore_filter')


#-------------------------------------------------------------------------
def check_recent_log(options):
    """
    Checks the most recent GPDB log file for warnings and errors related to standby master.
    Returns a tuple containing the warnings and the time of the last log entry.
    """
    warnings_errors = []
    recent_log      = get_most_recent_log(options)
    ignore_filter   = setup_ignore_filter(options)
    ignore_count    = 0
    how             = "Filtering" if ignore_filter is not None else "Examining"

    logger.info('%s log file %s for warnings and errors...' % (how, recent_log))

    lines = gp.GpLogFilter.local('log search', recent_log, trouble=True)
    for line in lines:

        # filter out lines matched by the ignore_filter
        if ignore_filter is not None and ignore_filter(line):
            ignore_count += 1
            continue

        # collect errors
        try:
            warnings_errors.append(line.split('|')[18])
        except Exception, e:
            # badly formatted log entry or empty line??
            logger.info(str(e))
            logger.info(line)
        
    # report lines ignored
    if ignore_filter is not None and ignore_count > 0:
        logger.info("Note: %d line(s) ignored by %s's ignore_filter" % (ignore_count, options.ignore))

    # get date from last line in log file
    last_entry_time = None
    last_line = gp.GpLogFilter.local('last log msg', recent_log, count=1)
    if last_line:
        last_entry_time = last_line[0].split('|')[0]

    return (warnings_errors, last_entry_time)


#-------------------------------------------------------------------------
def check_standby_master_activation(options):
    """Runs general sanity checks on the standby master looking for any
    obvious situations that would cause problems."""
    
    # Parse the most recent log file looking for sync errors and warnings.
    (warnings_errors, last_entry_time) = check_recent_log(options)
    return (warnings_errors, last_entry_time)


#-------------------------------------------------------------------------
def get_config():
    """Retrieves configuration information from the catalog."""
    
    logger.info('Reading current configuration...')
    dburl = dbconn.DbURL()
    array = gparray.GpArray.initFromCatalog(dburl, utility=True)
    
    master_hostname = array.master.getSegmentHostName()
    master_port = array.master.getSegmentPort()
    
    cmd = pg.ReadPostmasterTempFile.remote('Read postmaster file', master_port, master_hostname)
    (file_exists, _, _) = cmd.getResults()
    if file_exists:
        logger.warn('Appears that there is an active postgres process on %s port=%d' % (master_hostname, master_port))
        logger.info('This may have been caused by a kill -9 of the master postgres process.')
        logger.info('Traces of this process will need to be removed, please follow the instructions below.')
        logger.info('1. Delete the /tmp/.s.PGSQL.%d and /tmp/.s.PGSQL.%d.* files on %s' % (master_port, master_port, master_hostname))
        logger.info('2. Remove the %s/postmaster.pid file on %s' % (array.master.getSegmentDataDirectory(), master_hostname))
        logger.info('3. Then call this utility again.')
        stop_master()
        raise GpActivateStandbyException('Active postgres process on master')
    
    return array

#-------------------------------------------------------------------------
def update_flat_file(array, flat_file):
    """
        If the transaction/temporary filespaces have
        ever been moved, we need to update the flat file.
        The filespace directories are copied by the 
        copy_master_filespaces method.
    """

    logger.info('Updating filespace flat files')    

    pg_system_fs_entries = GetFilespaceEntriesDict(GetFilespaceEntries(array, PG_SYSTEM_FILESPACE).run()).run() 
   
    flat_file_location = os.path.join(pg_system_fs_entries[1][2], flat_file) 
        
    if not os.path.exists(flat_file_location):
        return

    logger.debug('flat file location for transaction files = %s' % flat_file_location)
    #Copy over the updated flat file to the standby
    with open(flat_file_location) as read_file:
        lines_to_write = ''
        for line in read_file:
            tokens = line.split()
            if len(tokens) != 2:
                lines_to_write += line
            elif tokens[0] == '1':
                lines_to_write += line

    temp_flat_file = os.path.join(flat_file_location + '.tmp')
    
    try:
        with open(temp_flat_file, 'w') as write_file:
            write_file.write(lines_to_write)
     
        #Rewrite the master flat file to include the standby information 
        shutil.move(temp_flat_file, flat_file_location)
    except Exception, e:
        raise Exception('Failed to update flat file')

def set_repair_global_sequence(datadir):
    """set gp_persistent_repair_global_sequenece for new standby master"""

    pool = WorkerPool()
    cmd = GpAddConfigScript(unix.getLocalHostname(), datadir, 'gp_persistent_repair_global_sequence', 'true', False)
    pool.addCommand(cmd)
    try:
        pool.join()
        items = pool.getCompletedItems()
        failure = False
        for i in items:
            if not i.was_successful():
                logger.error('failed updating the postgresql.conf files on host: ' + i.remoteHost)
                failure = True

        pool.check_results()
    except Exception, e:
        logger.error('errors in job:')
        logger.error(e.__str__())
        logger.error('exiting early')

    pool.haltWork()
    pool.joinWorkers()


def reset_repair_global_sequence(datadir):
    """reset gp_persistent_repair_global_sequenece after the activate standby"""
    pool = WorkerPool()
    cmd = GpAddConfigScript(unix.getLocalHostname(), datadir, 'gp_persistent_repair_global_sequence', None, True)
    pool.addCommand(cmd)
    try:
        pool.join()
        items = pool.getCompletedItems()
        failure = False
        for i in items:
            if not i.was_successful():
                logger.error('failed updating the postgresql.conf files on host: ' + i.remoteHost)
                failure = True

        pool.check_results()
    except Exception, e:
        logger.error('errors in job:')
        logger.error(e.__str__())
        logger.error('exiting early')

    pool.haltWork()
    pool.joinWorkers()


#-------------------------------------------------------------------------
def update_config():
    """Updates the configuration information in the catalog."""
    
    dburl = dbconn.DbURL()
    conn = dbconn.connect(dburl, utility=True)
    
    logger.info('Updating catalog...')
    sql = "SELECT gp_activate_standby()"
    dbconn.execSQL(conn, sql)

    conn.commit()
    conn.close()

    logger.info('Database catalog updated successful')

#-------------------------------------------------------------------------
def update_gpdbid_file(array):
    """Updates to gp_dbid file in the data directory to reflect the standby masters dbid."""
    
    standby_datadir = os.path.normpath(array.standbyMaster.getSegmentDataDirectory())

    # MPP-13245, use single mechanism to manage gp_dbid file instead of ad-hoc replace
    writeGpDbidFile(standby_datadir, 1, get_logger_if_verbose())


#-------------------------------------------------------------------------
def create_new_standby_master(options):
    """Creates a new standby master."""
    
    logger.info('Creating new standby master...')

    gphome = os.environ.get("GPHOME")
    # we have to use os.system here because gpinitstandby will be interactive
    # due to filespace remapping.
    rc = os.system("%s/bin/gpinitstandby -s %s" % (gphome, options.new_standby))
    if rc != 0:
        logger.warning('Failed to create the new standby master on %s' % options.new_standby)
        logger.warning('You will need to manually run \'gpinitstandby -s %s\' to create the new standby master.' % options.new_standby)
        raise GpActivateStandbyException('Failed to create new standby')


#-------------------------------------------------------------------------
def check_gpsync_running(options):
    """Checks if the gpsyncmaster process is running."""
    
    return gp.getSyncmasterPID('localhost', options.master_data_dir) > 0


#-------------------------------------------------------------------------
def stop_gpsync_process(options):
    """Stops the gpsyncmaster process."""
    
    logger.info('Stopping gpsync process...')

    # check to see if the gpsyncmaster process is active
    pid = gp.getSyncmasterPID('localhost', options.master_data_dir)
    
    if not pid > 0:
        # gpsyncmaster is not running so check if the force option was given.
        if options.force:
            # DbStatus only uses data directory so we can ignore the other values
            db = gparray.GpDB(None, None, None, None, None, None, None, None, None, options.master_data_dir, None)
            # check that postmaster isn't already running
            if pg.DbStatus.local('check db status', db) == True:
                logger.error('Located a postgres process on this host')
                logger.error('Has the master standby instance already been activated?')
                logger.error('Run the gpstate utility to check.')
                logger.error('Possible standby master instance active')
                raise GpActivateStandbyException('postgres process already running')
    else:
        gp.SegmentStop.local('stopping gpsyncmaster', options.master_data_dir, mode='fast')
        if unix.check_pid(pid):
            # not able to stop normally so give it a go with immediate mode
            logger.warning('Process gpsyncmaster still running, will issue fast shutdown with immediate')
            gp.SegmentStop.local('stopping gpsyncmaster', options.master_data_dir, mode='immediate')
                            
            if unix.check_pid(pid):
                logger.error('Unable to stop sync process')
                raise GpActivateStandbyException('Unable to stop sync process')
            else:
                logger.info('Successfully shutdown sync process.')
        else:
            logger.info('Successfully shutdown sync process')


#-------------------------------------------------------------------------
def start_master():
    """Starts the master."""
    
    logger.info('Starting standby master database in utility mode...')
    gp.GpStart.local('Start GPDB', masterOnly=True)


#-------------------------------------------------------------------------
def stop_master():
    """Stops the master."""
    
    logger.info('Stopping standby master...')
    gp.GpStop.local('Stop GPDB', masterOnly=True, fast=True)
    

#-------------------------------------------------------------------------
def start_database():
    """Starts the database."""
    
    logger.info('Starting database in production mode...')
    gp.GpStart.local('Start database in production mode')

#-------------------------------------------------------------------------
def stop_database():
    """Stops the database."""
    
    logger.info('Stopping database...')
    gp.GpStop.local('Stopping database')



#-------------------------------------------------------------------------
# Main
#-------------------------------------------------------------------------

# setup logging
logger = get_default_logger()
setup_tool_logging(EXECNAME, unix.getLocalHostname(), unix.getUserName())

# parse args and options
(options_, args_) = parseargs()

# if we got a new log dir, we can now set it up.
if options_.logfile:
    setup_tool_logging(EXECNAME, unix.getLocalHostname(), unix.getUserName(), logdir=options_.logfile)

try:
    (warnings_errors_, last_entry_time_) = check_standby_master_activation(options_)

    warnings_generated_ = print_summary(options_, warnings_errors_, last_entry_time_)

    # disable keyboard interrupt to prevent users from canceling
    # out of the process at a very bad time.  If there is a partial
    # update to the gp_configuration catalog and the user cancels
    # you get stuck where you can't go forward and you can't go
    # backwards.
    signal.signal(signal.SIGINT, signal.SIG_IGN)
    stop_gpsync_process(options_)
    # Prevent the global_sequence regression happened.
    set_repair_global_sequence(options_.master_data_dir)
    start_master()
    array_ = get_config()
    reset_repair_global_sequence(options_.master_data_dir)
    update_config()
    update_gpdbid_file(array_)
    update_flat_file(array_, GP_TRANSACTION_FILES_FILESPACE)
    update_flat_file(array_, GP_TEMPORARY_FILES_FILESPACE)

    # This should be stop_master, but due to filerep issue (MPP-9559)
    # we need to stop all the segments too.
    # Catch the exception that can be thrown if some segments are already down.
    try:
        stop_database()
    except Exception, e_:
        logger.info('Exception observed while stopping database')
        logger.info(str(e_))
 
    start_database()
    
    # At this point, cancel isn't all that bad so re-enable 
    # keyboard interrupt.  They may cancel out of the creating
    # of a new standby, but gpinitstandby can be used to 
    # create one at a later point.
    signal.signal(signal.SIGINT, signal.default_int_handler)
    
    if options_.new_standby:
        create_new_standby_master(options_)
        
    print_results(array_, unix.getLocalHostname(), options_)
    
    if warnings_generated_:
        sys.exit(1)
    else:
        sys.exit(0)
    
except Exception, e_:
    logger.fatal('Error activating standby master: %s' % str(e_))
    sys.exit(2)


